{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342d8371",
   "metadata": {},
   "source": [
    "# Rewards Allocation Notebook\n",
    "This goal of this notebook is to offer an easy way to process the outputs of the praise and sourcecred reward systems, calculate a reward distribution and perform an analysis of the results. It uses mock data and should be considered a work-in-progress. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d1675",
   "metadata": {},
   "source": [
    "### Basic Setup\n",
    "First, we import the relevant libraries, get the Data and set how many tokens we want to distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b54e374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Please choose the Praise CSV file == \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd1c62744a54abcb76a1a8273a43f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/dev/Documents/GitHub/praise_RewardAnalysis/exampleFiles', filename='', title='', show_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Please choose the Sourcecred CSV file == \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669620446d68497b9142f48d6b3c071f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/dev/Documents/GitHub/praise_RewardAnalysis/exampleFiles', filename='', title='', show_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Please choose the Rewardboard address list CSV file == \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb58e16d5504fd4917b1fb93bcd9d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/dev/Documents/GitHub/praise_RewardAnalysis/exampleFiles', filename='', title='', show_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import analytics_toolbox as tb\n",
    "\n",
    "fc_praise = FileChooser('./exampleFiles')\n",
    "fc_sourcecred = FileChooser('./exampleFiles')\n",
    "fc_rewardboard = FileChooser('./exampleFiles')\n",
    "\n",
    "print(\"== Please choose the Praise CSV file == \")\n",
    "display(fc_praise)\n",
    "print(\"== Please choose the Sourcecred CSV file == \")\n",
    "display(fc_sourcecred)\n",
    "print(\"== Please choose the Rewardboard address list CSV file == \")\n",
    "display(fc_rewardboard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b297b",
   "metadata": {},
   "source": [
    "Now that we have selected the files, we can import them for processing. We can also set the total amount of tokens we want to distribute this period.\n",
    "Tip: Now that the file paths are set, you can safely click on \"Cell > Run all below\" from here on the menu bar to execute everything :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e67fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRAISE_DATA_PATH = fc_praise.selected\n",
    "SOURCECRED_DATA_PATH = fc_sourcecred.selected\n",
    "REWARD_BOARD_ADDRESSES_PATH = fc_rewardboard.selected\n",
    "NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE = 1000\n",
    "\n",
    "praise_data = pd.read_csv(PRAISE_DATA_PATH)\n",
    "sourcecred_data = pd.read_csv(SOURCECRED_DATA_PATH)\n",
    "rewardboard_addresses = pd.read_csv(REWARD_BOARD_ADDRESSES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f52bdb",
   "metadata": {},
   "source": [
    "## Praise reward allocation\n",
    "This method allocates the praise rewards in a very straightforward way: It adds the value of all dished praised together, and then assigns to each user their % of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b41b12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_praise_rewards(praiseData, tokensToDistribute):\n",
    "    #we discard all we don't need and and aggregate all the praise for each single user\n",
    "    slimData = praiseData[['TO', 'FINAL QUANT']].groupby(['TO']).agg('sum').reset_index()\n",
    "    totalPraisePoints = slimData['FINAL QUANT'].sum()\n",
    "\n",
    "    slimData['PERCENTAGE'] = slimData['FINAL QUANT']/totalPraisePoints\n",
    "    slimData['TOKEN TO RECEIVE'] = slimData['PERCENTAGE'] * tokensToDistribute\n",
    "    return slimData\n",
    "\n",
    "praise_distribution = calc_praise_rewards(praise_data, NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ead318",
   "metadata": {},
   "source": [
    "## Combining the Datasets\n",
    "\n",
    "Now that we have the distribution done, we combine it with sourcecred into one table.\n",
    "But before continuing, we also want to declare some methods for cleaning the data and prepare it. We'll use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef2102ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Helper func. Puts all the \"processing we probably won't need to do later or do differently\" in one place\n",
    "#  -removes the '#' and following from discord names\n",
    "#  -Some renaming and dropping \n",
    "def prepare_praise(praise_data):\n",
    "    praise_data['TO'] = (praise_data['TO'].str.split('#', 1, expand=False).str[0]).str.lower()\n",
    "    praise_data.rename(columns = {'TO':'IDENTITY'}, inplace = True)\n",
    "    praise_data = praise_data[['IDENTITY', 'PERCENTAGE', 'TOKEN TO RECEIVE']]\n",
    "    return praise_data\n",
    "\n",
    "#General Helper func. Puts all the \"processing we probably won't need to do later or do differently\" in one place\n",
    "#  -Some renaming and dropping \n",
    "#  -changing percentages from 0 - 100 to 0.00-1.00\n",
    "def prepare_sourcecred(sourcecred_data):\n",
    "    sourcecred_data.rename(columns = {'%':'PERCENTAGE'}, inplace = True)\n",
    "    sourcecred_data['IDENTITY'] = sourcecred_data['IDENTITY'].str.lower()\n",
    "    sourcecred_data['PERCENTAGE'] = sourcecred_data['PERCENTAGE'] / 100\n",
    "    sourcecred_data = sourcecred_data[['IDENTITY', 'PERCENTAGE', 'TOKEN TO RECEIVE']]\n",
    "    return sourcecred_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996a728",
   "metadata": {},
   "source": [
    "Now we are ready to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa8e8c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   IDENTITY  PERCENTAGE  TOKEN TO RECEIVE\n",
      "0      bot0    0.065301       9232.792196\n",
      "1      bot1    0.035651        874.768741\n",
      "2     bot10    0.020120        492.898297\n",
      "3     bot11    0.037099        447.640907\n",
      "4     bot12    0.015800       2298.660294\n",
      "5     bot13    0.002305        461.040198\n",
      "6     bot14    0.044236       5788.186182\n",
      "7     bot15    0.024810       3033.389150\n",
      "8     bot16    0.055361       6738.384601\n",
      "9     bot17    0.000229         45.722995\n",
      "10    bot18    0.033679        444.571848\n",
      "11    bot19    0.054887      10977.329015\n",
      "12     bot2    0.020940        686.917526\n",
      "13    bot20    0.017429        544.097681\n",
      "14    bot21    0.017380        759.012890\n",
      "15    bot22    0.000972        194.322728\n",
      "16    bot23    0.006579        827.942152\n",
      "17    bot24    0.016495        232.914568\n",
      "18    bot25    0.032583       4629.464603\n",
      "19    bot26    0.027747       1790.681071\n",
      "20    bot27    0.003505        701.085921\n",
      "21    bot28    0.030522       2709.090576\n",
      "22    bot29    0.003544        708.706420\n",
      "23     bot3    0.100009      16469.289202\n",
      "24    bot30    0.011470       1067.824777\n",
      "25    bot31    0.001124        224.804725\n",
      "26    bot32    0.022138       4427.510002\n",
      "27    bot33    0.007468       1493.617832\n",
      "28    bot34    0.009259       1851.781292\n",
      "29    bot35    0.014112       1129.689980\n",
      "30    bot36    0.031954       1972.615075\n",
      "31    bot37    0.016712       1240.510334\n",
      "32    bot38    0.000438         87.635740\n",
      "33    bot39    0.004039        807.772909\n",
      "34     bot4    0.021090       4217.946275\n",
      "35    bot40    0.009411       1882.263288\n",
      "36    bot41    0.017858        167.740826\n",
      "37    bot42    0.020101        292.935038\n",
      "38    bot43    0.006693        145.411977\n",
      "39    bot44    0.006115       1223.090112\n",
      "40    bot45    0.002705        541.055439\n",
      "41    bot46    0.017449        400.796787\n",
      "42    bot47    0.038057         91.202439\n",
      "43    bot48    0.001638        327.681463\n",
      "44    bot49    0.005277       1055.439131\n",
      "45     bot5    0.005226         29.312401\n",
      "46     bot6    0.002305        461.040198\n",
      "47     bot7    0.035062       2548.425235\n",
      "48     bot8    0.005392       1078.300629\n",
      "49     bot9    0.019724       1144.686332\n"
     ]
    }
   ],
   "source": [
    "#generates a new table with combined percentages and added token rewards\n",
    "# ISSUE: We need single ids\n",
    "def combine_datasets(praise_data, sourcecred_data):\n",
    "    processed_praise = prepare_praise(praise_data)\n",
    "    processed_sourcecred = prepare_sourcecred(sourcecred_data)\n",
    "    combined_dataset = processed_praise.append(processed_sourcecred, ignore_index=True)\n",
    "\n",
    "    combined_dataset = combined_dataset.groupby(['IDENTITY']).agg('sum').reset_index()\n",
    "    #since we just added to percentages\n",
    "    combined_dataset['PERCENTAGE'] = combined_dataset['PERCENTAGE'] / 2\n",
    "\n",
    "\n",
    "    return combined_dataset\n",
    "\n",
    "\n",
    "total_period_rewards =combine_datasets(praise_distribution, sourcecred_data)\n",
    "print(total_period_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fd8ee",
   "metadata": {},
   "source": [
    "![title](img/praiseFusion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbd669",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "Let's dive into some data analysis! We'll use the metrics designed and explained by octopus🐙 for now, starting with:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85843373",
   "metadata": {},
   "source": [
    "### Allocation percentages\n",
    "This table will show us which percentage if the total rewards gets distributed to which top % of users. So \"Top 50% -> 0.85\" would mean that the top 50% of praisees received 85% of the total rewards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46405b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Rewards\n",
      "Top 50%  0.899760\n",
      "Top 20%  0.675479\n",
      "Top 10%  0.487188\n",
      "Top 5%   0.363162\n",
      "Top 1%   0.163062\n"
     ]
    }
   ],
   "source": [
    "p_vals = np.array([50,80,90,95,99])\n",
    "rewards_rp = np.array([tb.resource_percentage(total_period_rewards[\"TOKEN TO RECEIVE\"], p) for p in p_vals])\n",
    "\n",
    "my_rd_index = [(\"Top \" + str(100 - p) +\"%\") for p in p_vals]\n",
    "resource_distribution = pd.DataFrame({\"Rewards\": rewards_rp}, index = my_rd_index)\n",
    "print(resource_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d07afd0",
   "metadata": {},
   "source": [
    "### Gini coefficient\n",
    "Next we will look at the Gini coefficient. Note that there is some debate if we want to use this metric at all, since it is usually employed to measure wealth distribution, and not compensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c71f0155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Rewards\n",
      "All      0.629154\n",
      "Top 50%  0.471294\n",
      "Top 20%  0.311645\n"
     ]
    }
   ],
   "source": [
    "p_vals = np.array([0, 50, 80])\n",
    "rewards_gc = np.array([tb.gini_gt_p(np.array(total_period_rewards[\"TOKEN TO RECEIVE\"]), p) for p in p_vals])\n",
    "\n",
    "my_index = [\"All\", \"Top 50%\", \"Top 20%\"]\n",
    "gini_coefs = pd.DataFrame({\"Rewards\": rewards_gc}, index = my_index)\n",
    "print(gini_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10164d",
   "metadata": {},
   "source": [
    "### Shannon Entropy\n",
    "\n",
    "[Shannon Entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) is a concept from communications theory, which is also used in measuring the diversity of a distribution. The formula for calculating Shannon Entropy among $n$ individuals is\n",
    "    $$\\\\sum_{k=1}^n -p_k log_2(p_k),$$\n",
    "where $p_k$ represents the proportion of the resource that user $k$ received.\n",
    "\n",
    "Here we compare the actual Shannon Entropy with the maximum possible for the dataset, keeping in mind that a Shannon Entropy of 0 would mean one user holds all the rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "598539ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Rewards\n",
      "Entropy      5.051209\n",
      "Max Entropy  5.643856\n",
      "% of Max     0.894993\n"
     ]
    }
   ],
   "source": [
    "entropies_df = pd.DataFrame(data = {\"Rewards\" : tb.calc_shannon_entropies(total_period_rewards[\"PERCENTAGE\"]) }, index = [\"Entropy\", \"Max Entropy\", \"% of Max\"])\n",
    "print(entropies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50cebc",
   "metadata": {},
   "source": [
    "### Nakamoto Coefficient\n",
    "Last but not least, the Nakamoto coefficient. The Nakamato Coefficient is defined as the smallest number of accounts who control at least 50% of the resource. Although its significance relates to the prospect of a 51% attack on a network, which may not be relevant in our context, we can still use it as an intuitive measure of how many individuals received the majority of a resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61fe657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "ak_coef_IH = tb.nakamoto_coeff(total_period_rewards, \"PERCENTAGE\")\n",
    "print(ak_coef_IH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa451c",
   "metadata": {},
   "source": [
    "## Quantifier Data\n",
    "### Praise by Quantifier\n",
    "Let's take a closer look at each quantifier. In the following step we will use the raw praise data to zoom in on how each quantifier scored the praises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f1cbb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              QUANT_ID  PRAISE_ID  QUANT_VALUE\n",
      "0     0x000000000000000aafdb2ef4e870c8       1009           21\n",
      "1     0x000000000000000aafdb2ef4e870c8       1010          144\n",
      "2     0x000000000000000aafdb2ef4e870c8       1015          144\n",
      "3     0x000000000000000aafdb2ef4e870c8       1016            0\n",
      "4     0x000000000000000aafdb2ef4e870c8       1018           55\n",
      "...                                ...        ...          ...\n",
      "4495  0x00000000000000fa7c74e8880bb8d8       2489           13\n",
      "4496  0x00000000000000fa7c74e8880bb8d8       2490          144\n",
      "4497  0x00000000000000fa7c74e8880bb8d8       2492           21\n",
      "4498  0x00000000000000fa7c74e8880bb8d8       2493          144\n",
      "4499  0x00000000000000fa7c74e8880bb8d8       2498            0\n",
      "\n",
      "[4500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def data_by_quantifier(praise_data):\n",
    "    quant_only = pd.DataFrame()\n",
    "    praise_data.drop(['DATE', 'TO', 'FROM', 'REASON', 'SERVER', 'CHANNEL', 'CORRECTION ADD', 'CORRECTION SUB', 'CORRECTION COMMENT', 'FINAL QUANT'], axis=1, inplace=True)\n",
    "    num_of_quants = int((praise_data.shape[1] -1)/ 4)\n",
    "    for i in range(num_of_quants):\n",
    "        q_name =  str( 'QUANT_'+ str(i+1) +'_ID' )\n",
    "        q_value = str('QUANT_'+str(i+1) )\n",
    "        buf = praise_data[['ID', q_name , q_value ]].copy()\n",
    "    \n",
    "        buf.rename(columns={q_name: 'QUANT_ID', q_value: 'QUANT_VALUE', 'ID':'PRAISE_ID'}, inplace=True)\n",
    "        #print(buf)\n",
    "        quant_only = quant_only.append(buf.copy(), ignore_index=True)\n",
    "\n",
    "    columnsTitles = ['QUANT_ID', 'PRAISE_ID', 'QUANT_VALUE']\n",
    "    quant_only.sort_values(['QUANT_ID', 'PRAISE_ID'], inplace=True)\n",
    "    quant_only =  quant_only.reindex(columns=columnsTitles).reset_index(drop=True)\n",
    "    return quant_only\n",
    "\n",
    "quantifier_table = data_by_quantifier(praise_data.copy())\n",
    "print(quantifier_table)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c7dd1",
   "metadata": {},
   "source": [
    "### Amount of praise quantified\n",
    "With the above table we can easily see how much praise each quantifier rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba7fb9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      QUANT_ADDRESS  NUMBER_OF_PRAISES\n",
      "0  0x00000000000000f424831cf1d52bd3                463\n",
      "1  0x000000000000002e0a02e98b08c1fc                462\n",
      "2  0x000000000000008006d0ae0c65079b                462\n",
      "3  0x0000000000000034c5757446d67b52                456\n",
      "4  0x00000000000000fa7c74e8880bb8d8                453\n",
      "5  0x00000000000000ac2fc7fc8165773f                451\n",
      "6  0x00000000000000c60a37f0b254bffb                448\n",
      "7  0x000000000000000aafdb2ef4e870c8                444\n",
      "8  0x0000000000000022e76f033edab8d2                434\n",
      "9  0x000000000000006aa85e33191c824a                427\n"
     ]
    }
   ],
   "source": [
    "quant_praise_distribution = quantifier_table['QUANT_ID'].value_counts().reset_index().rename(columns={'index': 'QUANT_ADDRESS', 'QUANT_ID': 'NUMBER_OF_PRAISES'})\n",
    "print(quant_praise_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa014aa",
   "metadata": {},
   "source": [
    "## Total Praise Export\n",
    "To send the allocations to the Aragon DAO for distribution, we need to put all data together and add the rewards for the reward board and the quantifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45518c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ToDo\n",
    "def prepare_export_data(total_period_rewards, quantifier_table, rewardboard_addresses):\n",
    "    final_allocations = pd.DataFrame()\n",
    "    return final_allocations\n",
    "\n",
    "final_token_allocations = prepare_export_data(total_period_rewards, quantifier_table, rewardboard_addresses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
