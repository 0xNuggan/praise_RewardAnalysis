{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342d8371",
   "metadata": {},
   "source": [
    "# Rewards Allocation Notebook\n",
    "This goal of this notebook is to offer an easy way to process the outputs of the praise and sourcecred reward systems, calculate a reward distribution and perform an analysis of the results. It uses mock data and should be considered a work-in-progress. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d1675",
   "metadata": {},
   "source": [
    "### Basic Setup\n",
    "First, we import the relevant libraries, get the Data and set how many tokens we want to distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54e374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import analytics_toolbox as tb\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as pex\n",
    "\n",
    "fc_praise = FileChooser('./exampleFiles')\n",
    "fc_sourcecred = FileChooser('./exampleFiles')\n",
    "fc_rewardboard = FileChooser('./exampleFiles')\n",
    "\n",
    "print(\"== Please choose the Praise CSV file == \")\n",
    "display(fc_praise)\n",
    "print(\"== Please choose the Sourcecred CSV file == \")\n",
    "display(fc_sourcecred)\n",
    "print(\"== Please choose the Rewardboard address list CSV file == \")\n",
    "display(fc_rewardboard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b297b",
   "metadata": {},
   "source": [
    "Now that we have selected the files, we can import them for processing. We can also set the total amount of tokens we want to distribute this period.\n",
    "Tip: Now that the file paths are set, you can safely click on \"Cell > Run all below\" from here on the menu bar to execute everything :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e67fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRAISE_DATA_PATH = fc_praise.selected\n",
    "SOURCECRED_DATA_PATH = fc_sourcecred.selected\n",
    "REWARD_BOARD_ADDRESSES_PATH = fc_rewardboard.selected\n",
    "\n",
    "praise_data = pd.read_csv(PRAISE_DATA_PATH)\n",
    "sourcecred_data = pd.read_csv(SOURCECRED_DATA_PATH)\n",
    "rewardboard_addresses = pd.read_csv(REWARD_BOARD_ADDRESSES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98451b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE = 1950\n",
    "#Right now sourcecred rewards are calculated externally and already specified in the input. This may change.\n",
    "NUMBER_OF_SOURCECRED_REWARD_TOKENS_TO_DISTRIBUTE = 1950\n",
    "NUMBER_OF_REWARD_TOKENS_FOR_QUANTIFIERS = 1000\n",
    "NUMBER_OF_REWARD_TOKENS_FOR_REWARD_BOARD = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f52bdb",
   "metadata": {},
   "source": [
    "## Praise reward allocation\n",
    "This method allocates the praise rewards in a very straightforward way: It adds the value of all dished praised together, and then assigns to each user their % of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1577d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_praise_rewards(praiseData, tokensToDistribute):\n",
    "    #we discard all we don't need and and calculate the % worth of each praise\n",
    "    slimData = praiseData[['FROM', 'TO', 'FINAL QUANT']].copy()\n",
    "    totalPraisePoints = slimData['FINAL QUANT'].sum()\n",
    "\n",
    "    slimData['PERCENTAGE'] = slimData['FINAL QUANT']/totalPraisePoints\n",
    "    slimData['TOKEN TO RECEIVE'] = slimData['PERCENTAGE'] * tokensToDistribute\n",
    "    return slimData\n",
    "\n",
    "praise_distribution = calc_praise_rewards(praise_data.copy(), NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE)\n",
    "praise_distribution\n",
    "\n",
    "#TO DO: show the whole table!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ead318",
   "metadata": {},
   "source": [
    "## Combining the Datasets\n",
    "\n",
    "Now that we have the distribution done, we combine it with sourcecred into one table.\n",
    "But before continuing, we also want to declare some methods for cleaning the data and prepare it. We'll use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2102ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Helper func. Puts all the \"processing we probably won't need to do later or do differently\" in one place\n",
    "#  -removes the '#' and following from discord names\n",
    "#  -Some renaming and dropping \n",
    "def prepare_praise(praise_data):\n",
    "    praise_data['TO'] = (praise_data['TO'].str.split('#', 1, expand=False).str[0]).str.lower()\n",
    "    praise_data.rename(columns = {'TO':'IDENTITY'}, inplace = True)\n",
    "    praise_data = praise_data[['IDENTITY', 'PERCENTAGE', 'TOKEN TO RECEIVE']]\n",
    "    return praise_data\n",
    "\n",
    "#General Helper func. Puts all the \"processing we probably won't need to do later or do differently\" in one place\n",
    "#  -Some renaming and dropping \n",
    "#  -changing percentages from 0 - 100 to 0.00-1.00\n",
    "def prepare_sourcecred(sourcecred_data):\n",
    "    sourcecred_data.rename(columns = {'%':'PERCENTAGE'}, inplace = True)\n",
    "    sourcecred_data['IDENTITY'] = sourcecred_data['IDENTITY'].str.lower()\n",
    "    sourcecred_data['PERCENTAGE'] = sourcecred_data['PERCENTAGE'] / 100\n",
    "    sourcecred_data = sourcecred_data[['IDENTITY', 'PERCENTAGE', 'TOKEN TO RECEIVE']]\n",
    "    return sourcecred_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996a728",
   "metadata": {},
   "source": [
    "Now we are ready to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates a new table with combined percentages and added token rewards\n",
    "# TO DO adapt in case sourcecred stops sending the allocated token number\n",
    "def combine_datasets(praise_data, sourcecred_data):\n",
    "    processed_praise = prepare_praise(praise_data)\n",
    "    processed_praise = processed_praise[['IDENTITY', 'PERCENTAGE', 'TOKEN TO RECEIVE']].groupby(['IDENTITY']).agg('sum').reset_index()\n",
    "    processed_sourcecred = prepare_sourcecred(sourcecred_data)\n",
    "    combined_dataset = processed_praise.append(processed_sourcecred, ignore_index=True)\n",
    "\n",
    "    combined_dataset = combined_dataset.groupby(['IDENTITY']).agg('sum').reset_index()\n",
    "    #since we just added to percentages\n",
    "    combined_dataset['PERCENTAGE'] = combined_dataset['PERCENTAGE'] / 2\n",
    "\n",
    "\n",
    "    return combined_dataset\n",
    "\n",
    "\n",
    "total_period_rewards =combine_datasets(praise_distribution.copy(), sourcecred_data.copy())\n",
    "total_period_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fd8ee",
   "metadata": {},
   "source": [
    "![title](img/praiseFusion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbd669",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "Let's dive into some data analysis! We'll use the metrics designed and explained by octopus🐙 for now, starting with:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85843373",
   "metadata": {},
   "source": [
    "### Allocation percentages\n",
    "This table will show us which percentage if the total rewards gets distributed to which top % of users. So \"Top 50% -> 0.85\" would mean that the top 50% of praisees received 85% of the total rewards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46405b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals = np.array([50,80,90,95,99])\n",
    "rewards_rp = np.array([tb.resource_percentage(total_period_rewards[\"TOKEN TO RECEIVE\"], p) for p in p_vals])\n",
    "\n",
    "my_rd_index = [(\"Top \" + str(100 - p) +\"%\") for p in p_vals]\n",
    "resource_distribution = pd.DataFrame({\"Rewards\": rewards_rp}, index = my_rd_index)\n",
    "print(resource_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d07afd0",
   "metadata": {},
   "source": [
    "### Gini coefficient\n",
    "Next we will look at the Gini coefficient. Note that there is some debate if we want to use this metric at all, since it is usually employed to measure wealth distribution, and not compensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals = np.array([0, 50, 80])\n",
    "rewards_gc = np.array([tb.gini_gt_p(np.array(total_period_rewards[\"TOKEN TO RECEIVE\"]), p) for p in p_vals])\n",
    "\n",
    "my_index = [\"All\", \"Top 50%\", \"Top 20%\"]\n",
    "gini_coefs = pd.DataFrame({\"Rewards\": rewards_gc}, index = my_index)\n",
    "print(gini_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10164d",
   "metadata": {},
   "source": [
    "### Shannon Entropy\n",
    "\n",
    "[Shannon Entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) is a concept from communications theory, which is also used in measuring the diversity of a distribution. The formula for calculating Shannon Entropy among $n$ individuals is\n",
    "    $$\\\\sum_{k=1}^n -p_k log_2(p_k),$$\n",
    "where $p_k$ represents the proportion of the resource that user $k$ received.\n",
    "\n",
    "Here we compare the actual Shannon Entropy with the maximum possible for the dataset, keeping in mind that a Shannon Entropy of 0 would mean one user holds all the rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598539ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies_df = pd.DataFrame(data = {\"Rewards\" : tb.calc_shannon_entropies(total_period_rewards[\"PERCENTAGE\"]) }, index = [\"Entropy\", \"Max Entropy\", \"% of Max\"])\n",
    "print(entropies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50cebc",
   "metadata": {},
   "source": [
    "### Nakamoto Coefficient\n",
    "Last but not least, the Nakamoto coefficient. The Nakamato Coefficient is defined as the smallest number of accounts who control at least 50% of the resource. Although its significance relates to the prospect of a 51% attack on a network, which may not be relevant in our context, we can still use it as an intuitive measure of how many individuals received the majority of a resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak_coef_IH = tb.nakamoto_coeff(total_period_rewards, \"PERCENTAGE\")\n",
    "print(ak_coef_IH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa451c",
   "metadata": {},
   "source": [
    "## Quantifier Data\n",
    "### Praise by Quantifier\n",
    "Let's take a closer look at each quantifier. In the following step we will use the raw praise data to zoom in on how each quantifier scored the praises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1cbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_by_quantifier(praise_data):\n",
    "    quant_only = pd.DataFrame()\n",
    "    praise_data.drop(['DATE', 'TO', 'FROM', 'REASON', 'SERVER', 'CHANNEL', 'CORRECTION ADD', 'CORRECTION SUB', 'CORRECTION COMMENT', 'FINAL QUANT'], axis=1, inplace=True)\n",
    "    num_of_quants = int((praise_data.shape[1] -1)/ 4)\n",
    "    for i in range(num_of_quants):\n",
    "        q_name =  str( 'QUANT_'+ str(i+1) +'_ID' )\n",
    "        q_value = str('QUANT_'+str(i+1) )\n",
    "        buf = praise_data[['ID', q_name , q_value ]].copy()\n",
    "    \n",
    "        buf.rename(columns={q_name: 'QUANT_ID', q_value: 'QUANT_VALUE', 'ID':'PRAISE_ID'}, inplace=True)\n",
    "        #print(buf)\n",
    "        quant_only = quant_only.append(buf.copy(), ignore_index=True)\n",
    "\n",
    "    columnsTitles = ['QUANT_ID', 'PRAISE_ID', 'QUANT_VALUE']\n",
    "    quant_only.sort_values(['QUANT_ID', 'PRAISE_ID'], inplace=True)\n",
    "    quant_only =  quant_only.reindex(columns=columnsTitles).reset_index(drop=True)\n",
    "    return quant_only\n",
    "\n",
    "quantifier_table = data_by_quantifier(praise_data.copy())\n",
    "quantifier_table \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c7dd1",
   "metadata": {},
   "source": [
    "### Amount of praise quantified\n",
    "With the above table we can easily see how much praise each quantifier rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_praise_distribution = quantifier_table['QUANT_ID'].value_counts().reset_index().rename(columns={'index': 'QUANT_ADDRESS', 'QUANT_ID': 'NUMBER_OF_PRAISES'})\n",
    "quant_praise_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17443ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pex.pie(quant_praise_distribution, values='NUMBER_OF_PRAISES', names='QUANT_ADDRESS', title='Amount of praise by each quantifier')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f5528f",
   "metadata": {},
   "source": [
    "### Praise Flows\n",
    "\n",
    "We can also take a look at the top \"praise flows\". Thanks to @inventandchill for this awesome visualization! \n",
    "On one side we have the top 10 praise givers separately (modifiable by changing the variable n_senders), on the other the top 15 receivers (modifiable by changing the variable n_receivers). The people outside the selection get aggregated into the \"REST FROM\" and \"REST TO\" categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb60f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac68804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_senders: Left side. Praise senders. n largest ones + rest (others)\n",
    "#n_receivers: Right side. Praise receivers. n largest ones + rest (others)\n",
    "praise_flow = tb.prepare_praise_flow(praise_distribution.copy(), n_senders=10, n_receivers=15)\n",
    "praise_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Sankey (cmap='Category10' edge_color='FROM' edge_line_width=0 node_alpha=1.0)\n",
    "%%opts Sankey [node_sort=False label_position='outer' bgcolor=\"snow\" node_width=40 node_sort=True ]\n",
    "%%opts Sankey [width=1200 height=1000 title=\"Praise flow for Batch 1. Sum of Praise. Left - praise sender. Right - praise receiver\"]\n",
    "%%opts Sankey [margin=0 padding=0 show_values=True]\n",
    "\n",
    "hv.Sankey(praise_flow, kdims=[\"FROM\", \"TO\"], vdims=[\"FINAL QUANT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a649b073",
   "metadata": {},
   "source": [
    "### Histogram of Received Praise\n",
    "\n",
    "Next we can see the distribution of the dished praise, i.e. \"How many people had X amount of praise?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c09159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_h=praise_distribution['FINAL QUANT'].copy()\n",
    "#df_h.reset_index(inplace=True, drop = False)\n",
    "frequencies, edges = np.histogram(praise_distribution['FINAL QUANT'], 200)\n",
    "print('Values: %s, Edges: %s' % (frequencies.shape[0], edges.shape[0]))\n",
    "\n",
    "#%%opts Histogram (cmap='Category10' edge_color='From' edge_line_width=0 node_alpha=1.0)\n",
    "#%%opts Histogram [node_sort=False label_position='outer' bgcolor=\"snow\" node_width=40 node_sort=True ]\n",
    "#%%opts histogram [width=1200 height=1000 title=\"Praise flow for Batch 3. Sum of Praise. Left - praise sender. Right - praise receiver\"]\n",
    "#%%opts Sankey [margin=0 padding=0 show_values=True]\n",
    "hv.Histogram((edges, frequencies)).opts(width=800, height=500, title='Praise amount histogram for Batch 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa014aa",
   "metadata": {},
   "source": [
    "## Total Token Distribution Export\n",
    "To send the allocations to the DAO for distribution, we need to put all data together and add the rewards for the reward board and the quantifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da063606",
   "metadata": {},
   "source": [
    "First, we will calculate the rewards for the Quantifiers and the Reward Board. This is fairly straightforward, since we distribute the allocated tokens equally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728fc629",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantifier_rewards = pd.DataFrame(quant_praise_distribution['QUANT_ADDRESS'].copy())\n",
    "quantifier_rewards['TOKEN TO RECEIVE'] = NUMBER_OF_REWARD_TOKENS_FOR_QUANTIFIERS / len(quantifier_rewards.index)\n",
    "quantifier_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f56fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewardboard_rewards = pd.DataFrame(rewardboard_addresses)\n",
    "rewardboard_rewards['TOKEN TO RECEIVE'] = NUMBER_OF_REWARD_TOKENS_FOR_REWARD_BOARD / len(rewardboard_rewards.index)\n",
    "rewardboard_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ccefe",
   "metadata": {},
   "source": [
    "Now we can merge them all into one table and save it, ready for distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45518c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Do: export it to csv\n",
    "def prepare_export_data(total_period_rewards, quantifier_rewards, rewardboard_rewards):\n",
    "    quantifier_rewards.rename(columns = {'QUANT_ADDRESS':'IDENTITY'}, inplace = True)\n",
    "    rewardboard_rewards.rename(columns = {'ID':'IDENTITY'}, inplace = True)\n",
    "    final_allocations = pd.DataFrame(total_period_rewards[['IDENTITY', 'TOKEN TO RECEIVE']])\n",
    "    final_allocations = final_allocations.append(quantifier_rewards)\n",
    "    final_allocations = final_allocations.append(rewardboard_rewards)\n",
    "    final_allocations = final_allocations.reset_index(drop=True)\n",
    "    return final_allocations\n",
    "\n",
    "final_token_allocations = prepare_export_data(total_period_rewards, quantifier_rewards, rewardboard_rewards)\n",
    "final_token_allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743e42c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
